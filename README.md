# When ChatGPT was told to write as a news reporter: How to detect AI-generated disinformation

Generative AI can rapidly produce fabricated health-related news that threatens public health, erodes trust, and induces unrest. While certain features aiding in the differentiation between fake and real news have been identified, the effectiveness of these markers is compromised by the AI’s ability to closely replicate the writing style of trusted sources. This study aims to identify linguistic, semantic, and topic-related features that human observers can uniquely associate with AI-generated misinformation. Utilizing Natural Language Processing (NLP) techniques, this research analyzes features in health news generated by the advanced GPT-3.5 Turbo large language model, comparing them to those in human-written articles. Key findings highlight that AI-generated misinformation tends to feature shorter sentences, fewer verifiable facts, and a higher level of affirmativeness, subjectivity, and emotional content compared to authentic news. These insights are crucial for understanding AI-fabricated content’s nature and are instrumental in developing automated detection tools in the future.
